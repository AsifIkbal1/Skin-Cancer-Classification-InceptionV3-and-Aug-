{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Step 1 : Importing Essetial Libraries","metadata":{"papermill":{"duration":0.010801,"end_time":"2023-04-08T14:54:29.68854","exception":false,"start_time":"2023-04-08T14:54:29.677739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nfrom PIL import Image\n\nimport keras\nfrom keras.utils.np_utils import to_categorical # used for converting labels to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":9.222684,"end_time":"2023-04-08T14:54:38.921024","exception":false,"start_time":"2023-04-08T14:54:29.69834","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:07.41687Z","iopub.execute_input":"2023-04-13T09:28:07.417363Z","iopub.status.idle":"2023-04-13T09:28:17.882251Z","shell.execute_reply.started":"2023-04-13T09:28:07.417314Z","shell.execute_reply":"2023-04-13T09:28:17.881131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 2 : Importing Data and Creating a Dataframe","metadata":{"papermill":{"duration":0.00893,"end_time":"2023-04-08T14:54:38.939672","exception":false,"start_time":"2023-04-08T14:54:38.930742","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\ntrain_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Train'\ntest_dir = '/kaggle/input/skin-cancer9-classesisic/Skin cancer ISIC The International Skin Imaging Collaboration/Test'\n\n# Create dataframes\ntrain_df = pd.DataFrame(columns=['image_path', 'label'])\ntest_df = pd.DataFrame(columns=['image_path', 'label'])\n\n# Add images paths and labels to dataframes\nfor label, directory in enumerate(os.listdir(train_dir)):\n    for filename in os.listdir(os.path.join(train_dir, directory)):\n        image_path = os.path.join(train_dir, directory, filename)\n        train_df = train_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n\nfor label, directory in enumerate(os.listdir(test_dir)):\n    for filename in os.listdir(os.path.join(test_dir, directory)):\n        image_path = os.path.join(test_dir, directory, filename)\n        test_df = test_df.append({'image_path': image_path, 'label': label}, ignore_index=True)\n        \n# Combine train_df and test_df into one dataframe\ndf = pd.concat([train_df, test_df], ignore_index=True)\ndel test_df,train_df\ndf","metadata":{"papermill":{"duration":4.466736,"end_time":"2023-04-08T14:54:43.416586","exception":false,"start_time":"2023-04-08T14:54:38.94985","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:17.884488Z","iopub.execute_input":"2023-04-13T09:28:17.885871Z","iopub.status.idle":"2023-04-13T09:28:22.599571Z","shell.execute_reply.started":"2023-04-13T09:28:17.885828Z","shell.execute_reply":"2023-04-13T09:28:22.598485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get list of directories in train_dir\nlabels = os.listdir(train_dir)\n\n# Create label_map dictionary\nlabel_map = {i: label for i, label in enumerate(labels)}\nnum_classes=len(label_map)\nlabel_map","metadata":{"papermill":{"duration":0.020698,"end_time":"2023-04-08T14:54:43.522854","exception":false,"start_time":"2023-04-08T14:54:43.502156","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:22.601002Z","iopub.execute_input":"2023-04-13T09:28:22.601623Z","iopub.status.idle":"2023-04-13T09:28:22.611574Z","shell.execute_reply.started":"2023-04-13T09:28:22.601584Z","shell.execute_reply":"2023-04-13T09:28:22.610508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 3 : EDA","metadata":{"papermill":{"duration":0.009509,"end_time":"2023-04-08T14:54:43.570674","exception":false,"start_time":"2023-04-08T14:54:43.561165","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Plot pie chart of train_df\ndf['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\nplt.axis('equal')\nplt.title('Distribution of Labels in DataFrame')\nplt.legend(df['label'].unique())\nplt.show()","metadata":{"papermill":{"duration":0.372667,"end_time":"2023-04-08T14:54:43.953259","exception":false,"start_time":"2023-04-08T14:54:43.580592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:22.613257Z","iopub.execute_input":"2023-04-13T09:28:22.613517Z","iopub.status.idle":"2023-04-13T09:28:22.972461Z","shell.execute_reply.started":"2023-04-13T09:28:22.613491Z","shell.execute_reply":"2023-04-13T09:28:22.971388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:28:22.975861Z","iopub.execute_input":"2023-04-13T09:28:22.97657Z","iopub.status.idle":"2023-04-13T09:28:22.987058Z","shell.execute_reply.started":"2023-04-13T09:28:22.976517Z","shell.execute_reply":"2023-04-13T09:28:22.98593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 4 : Loading and resizing of images","metadata":{"papermill":{"duration":0.010587,"end_time":"2023-04-08T14:54:43.974718","exception":false,"start_time":"2023-04-08T14:54:43.964131","status":"completed"},"tags":[]}},{"cell_type":"code","source":"max_images_per_class = 2500\n\n# Group by label column and take first max_images_per_class rows for each group\ndf = df.groupby(\"label\").apply(lambda x: x.head(max_images_per_class)).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:28:22.988791Z","iopub.execute_input":"2023-04-13T09:28:22.989166Z","iopub.status.idle":"2023-04-13T09:28:23.004523Z","shell.execute_reply.started":"2023-04-13T09:28:22.98913Z","shell.execute_reply":"2023-04-13T09:28:23.003368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\n# Allow gpu usage\ngpus = tf.config.experimental.list_physical_devices('GPU')\nprint(gpus)\ntry:\n    tf.config.experimental.set_memory_growth = True\nexcept Exception as ex:\n    print(e)","metadata":{"papermill":{"duration":0.316802,"end_time":"2023-04-08T14:54:44.301568","exception":false,"start_time":"2023-04-08T14:54:43.984766","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:23.00583Z","iopub.execute_input":"2023-04-13T09:28:23.006618Z","iopub.status.idle":"2023-04-13T09:28:23.338042Z","shell.execute_reply.started":"2023-04-13T09:28:23.006582Z","shell.execute_reply":"2023-04-13T09:28:23.336842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\n# Get the number of CPU cores available\nmax_workers = multiprocessing.cpu_count()\nmax_workers","metadata":{"papermill":{"duration":0.020755,"end_time":"2023-04-08T14:54:44.332822","exception":false,"start_time":"2023-04-08T14:54:44.312067","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:23.339915Z","iopub.execute_input":"2023-04-13T09:28:23.340772Z","iopub.status.idle":"2023-04-13T09:28:23.35467Z","shell.execute_reply.started":"2023-04-13T09:28:23.340727Z","shell.execute_reply":"2023-04-13T09:28:23.353695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import concurrent.futures\n\n# Define a function to resize image arrays\ndef resize_image_array(image_path):\n    return np.asarray(Image.open(image_path).resize((100,75)))\n\n# Use concurrent.futures to parallelize the resizing process\nwith concurrent.futures.ThreadPoolExecutor(max_workers=max_workers*10) as executor:\n    # Use executor.map to apply the function to each image path in the DataFrame\n    image_arrays = list(executor.map(resize_image_array, df['image_path'].tolist()))\n\n# Add the resized image arrays to the DataFrame\ndf['image'] = image_arrays\ndel image_arrays","metadata":{"papermill":{"duration":51.02496,"end_time":"2023-04-08T14:55:35.368114","exception":false,"start_time":"2023-04-08T14:54:44.343154","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:28:23.35625Z","iopub.execute_input":"2023-04-13T09:28:23.356802Z","iopub.status.idle":"2023-04-13T09:29:13.780025Z","shell.execute_reply.started":"2023-04-13T09:28:23.356765Z","shell.execute_reply":"2023-04-13T09:29:13.778675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":9.082972,"end_time":"2023-04-08T14:55:44.462695","exception":false,"start_time":"2023-04-08T14:55:35.379723","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:29:13.781259Z","iopub.execute_input":"2023-04-13T09:29:13.781648Z","iopub.status.idle":"2023-04-13T09:29:22.937661Z","shell.execute_reply.started":"2023-04-13T09:29:13.781608Z","shell.execute_reply":"2023-04-13T09:29:22.936565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class before Data Augmentation","metadata":{}},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:29:22.939093Z","iopub.execute_input":"2023-04-13T09:29:22.939742Z","iopub.status.idle":"2023-04-13T09:29:22.951362Z","shell.execute_reply.started":"2023-04-13T09:29:22.939704Z","shell.execute_reply":"2023-04-13T09:29:22.950331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = 7\nfig, m_axs = plt.subplots(num_classes, n_samples, figsize=(4*n_samples, 3*7))\nfor n_axs, (class_idx, class_rows) in zip(m_axs, df.sort_values(['label']).groupby('label')):\n    class_name = label_map[class_idx] # get the class name using label_map\n    n_axs[0].set_title(class_name)\n    for c_ax, (_, c_row) in zip(n_axs, class_rows.sample(n_samples, random_state=5).iterrows()):\n        c_ax.imshow(c_row['image'])\n        c_ax.axis('off')","metadata":{"papermill":{"duration":3.775445,"end_time":"2023-04-08T14:55:48.249354","exception":false,"start_time":"2023-04-08T14:55:44.473909","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:29:23.26205Z","iopub.execute_input":"2023-04-13T09:29:23.26521Z","iopub.status.idle":"2023-04-13T09:29:26.783988Z","shell.execute_reply.started":"2023-04-13T09:29:23.265178Z","shell.execute_reply":"2023-04-13T09:29:26.782648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['image'].map(lambda x: x.shape).value_counts()","metadata":{"papermill":{"duration":0.061411,"end_time":"2023-04-08T14:55:48.357706","exception":false,"start_time":"2023-04-08T14:55:48.296295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:29:26.791324Z","iopub.execute_input":"2023-04-13T09:29:26.792018Z","iopub.status.idle":"2023-04-13T09:29:26.804241Z","shell.execute_reply.started":"2023-04-13T09:29:26.791978Z","shell.execute_reply":"2023-04-13T09:29:26.803066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5 : Data Augmentation","metadata":{"papermill":{"duration":0.047425,"end_time":"2023-04-08T14:56:00.20678","exception":false,"start_time":"2023-04-08T14:56:00.159355","status":"completed"},"tags":[]}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n# Create an ImageDataGenerator object with the desired transformations\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:29:26.805616Z","iopub.execute_input":"2023-04-13T09:29:26.805902Z","iopub.status.idle":"2023-04-13T09:29:26.813059Z","shell.execute_reply.started":"2023-04-13T09:29:26.805875Z","shell.execute_reply":"2023-04-13T09:29:26.811961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an empty dataframe to store the augmented images\naugmented_df = pd.DataFrame(columns=['image_path', 'label', 'image'])\n\n# Loop through each class label and generate additional images if needed\nfor class_label in df['label'].unique():\n    # Get the image arrays for the current class\n    image_arrays = df.loc[df['label'] == class_label, 'image'].values\n    \n    # Calculate the number of additional images needed for the current class\n    num_images_needed = max_images_per_class - len(image_arrays)\n    \n    # Generate augmented images for the current class\n    if num_images_needed > 0:\n        # Select a random subset of the original images\n        selected_images = np.random.choice(image_arrays, size=num_images_needed)\n        \n        # Apply transformations to the selected images and add them to the augmented dataframe\n        for image_array in selected_images:\n            # Reshape the image array to a 4D tensor with a batch size of 1\n            image_tensor = np.expand_dims(image_array, axis=0)\n            \n            # Generate the augmented images\n            augmented_images = datagen.flow(image_tensor, batch_size=1)\n            \n            # Extract the augmented image arrays and add them to the augmented dataframe\n            for i in range(augmented_images.n):\n                augmented_image_array = augmented_images.next()[0].astype('uint8')\n                augmented_df = augmented_df.append({'image_path': None, 'label': class_label, 'image': augmented_image_array}, ignore_index=True)\n    \n    # Add the original images for the current class to the augmented dataframe\n    original_images_df = df.loc[df['label'] == class_label, ['image_path', 'label', 'image']]\n    augmented_df = augmented_df.append(original_images_df, ignore_index=True)\n\n# Group the augmented dataframe by the 'label' column and filter out extra images\ndf = augmented_df.groupby('label').head(max_images_per_class)\n\ndel augmented_df\n\n# Use the augmented dataframe for further processing\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:29:26.815086Z","iopub.execute_input":"2023-04-13T09:29:26.816021Z","iopub.status.idle":"2023-04-13T09:31:01.990988Z","shell.execute_reply.started":"2023-04-13T09:29:26.815985Z","shell.execute_reply":"2023-04-13T09:31:01.989904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class after Data Augmentation","metadata":{"papermill":{"duration":0.046393,"end_time":"2023-04-08T14:56:00.879027","exception":false,"start_time":"2023-04-08T14:56:00.832634","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Plot pie chart of train_df\ndf['label'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=90)\nplt.axis('equal')\nplt.title('Distribution of Labels in DataFrame')\nplt.legend(df['label'].unique())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:29:22.953043Z","iopub.execute_input":"2023-04-13T09:29:22.953826Z","iopub.status.idle":"2023-04-13T09:29:23.260533Z","shell.execute_reply.started":"2023-04-13T09:29:22.953789Z","shell.execute_reply":"2023-04-13T09:29:23.259522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of images in each class\nclass_counts = df['label'].value_counts().sort_index()\n\n# Print the number of images in each class\nprint(\"Dataset Summary\")\nprint(\"-\" * 60)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Count':<10}\")\nprint(\"-\" * 60)\nfor class_label, class_name in label_map.items():\n    count = class_counts[class_label]\n    print(f\"{class_label:<15} {class_name:<30} {count:<10}\")\nprint(\"-\" * 60)\nprint(f\"{'Total':<45} {sum(class_counts):<10}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:31:01.994437Z","iopub.execute_input":"2023-04-13T09:31:01.994926Z","iopub.status.idle":"2023-04-13T09:31:02.005467Z","shell.execute_reply.started":"2023-04-13T09:31:01.994887Z","shell.execute_reply":"2023-04-13T09:31:02.004262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6 : Train and Test split","metadata":{"papermill":{"duration":0.046342,"end_time":"2023-04-08T14:55:48.448187","exception":false,"start_time":"2023-04-08T14:55:48.401845","status":"completed"},"tags":[]}},{"cell_type":"code","source":"features = df.drop(columns=['label','image_path'],axis=1)\ntarget = df['label']","metadata":{"papermill":{"duration":0.056845,"end_time":"2023-04-08T14:55:48.551537","exception":false,"start_time":"2023-04-08T14:55:48.494692","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:02.007066Z","iopub.execute_input":"2023-04-13T09:31:02.007435Z","iopub.status.idle":"2023-04-13T09:31:02.030042Z","shell.execute_reply.started":"2023-04-13T09:31:02.007399Z","shell.execute_reply":"2023-04-13T09:31:02.028936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"papermill":{"duration":9.197518,"end_time":"2023-04-08T14:55:57.793734","exception":false,"start_time":"2023-04-08T14:55:48.596216","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:02.033178Z","iopub.execute_input":"2023-04-13T09:31:02.033533Z","iopub.status.idle":"2023-04-13T09:31:11.140602Z","shell.execute_reply.started":"2023-04-13T09:31:02.033507Z","shell.execute_reply":"2023-04-13T09:31:11.139549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.head()","metadata":{"papermill":{"duration":0.057596,"end_time":"2023-04-08T14:55:57.896986","exception":false,"start_time":"2023-04-08T14:55:57.83939","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:11.141904Z","iopub.execute_input":"2023-04-13T09:31:11.14255Z","iopub.status.idle":"2023-04-13T09:31:11.149835Z","shell.execute_reply.started":"2023-04-13T09:31:11.14251Z","shell.execute_reply":"2023-04-13T09:31:11.148764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(target.shape,features.shape)","metadata":{"papermill":{"duration":0.058722,"end_time":"2023-04-08T14:55:58.000264","exception":false,"start_time":"2023-04-08T14:55:57.941542","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:11.151426Z","iopub.execute_input":"2023-04-13T09:31:11.152064Z","iopub.status.idle":"2023-04-13T09:31:11.160848Z","shell.execute_reply.started":"2023-04-13T09:31:11.152028Z","shell.execute_reply":"2023-04-13T09:31:11.15962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.20,shuffle=True)","metadata":{"papermill":{"duration":0.073134,"end_time":"2023-04-08T14:55:58.119128","exception":false,"start_time":"2023-04-08T14:55:58.045994","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:11.162544Z","iopub.execute_input":"2023-04-13T09:31:11.162897Z","iopub.status.idle":"2023-04-13T09:31:11.177544Z","shell.execute_reply.started":"2023-04-13T09:31:11.162863Z","shell.execute_reply":"2023-04-13T09:31:11.176422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7 : Normalization of Data","metadata":{"papermill":{"duration":0.07358,"end_time":"2023-04-08T14:55:58.265239","exception":false,"start_time":"2023-04-08T14:55:58.191659","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x_train = np.asarray(x_train['image'].tolist())\nx_test = np.asarray(x_test['image'].tolist())\n\nx_train_mean = np.mean(x_train)\nx_train_std = np.std(x_train)\nx_test_mean = np.mean(x_test)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean)/x_train_std\nx_test = (x_test - x_test_mean)/x_test_std","metadata":{"papermill":{"duration":0.668418,"end_time":"2023-04-08T14:55:59.006266","exception":false,"start_time":"2023-04-08T14:55:58.337848","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:11.17926Z","iopub.execute_input":"2023-04-13T09:31:11.17967Z","iopub.status.idle":"2023-04-13T09:31:15.522153Z","shell.execute_reply.started":"2023-04-13T09:31:11.179635Z","shell.execute_reply":"2023-04-13T09:31:15.521024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 8 : Label Encoding","metadata":{"papermill":{"duration":0.078137,"end_time":"2023-04-08T14:55:59.163475","exception":false,"start_time":"2023-04-08T14:55:59.085338","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Perform one-hot encoding on the labels\ny_train = to_categorical(y_train,num_classes = num_classes)\ny_test = to_categorical(y_test,num_classes = num_classes)","metadata":{"papermill":{"duration":0.08297,"end_time":"2023-04-08T14:55:59.322888","exception":false,"start_time":"2023-04-08T14:55:59.239918","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:15.523997Z","iopub.execute_input":"2023-04-13T09:31:15.524331Z","iopub.status.idle":"2023-04-13T09:31:15.532251Z","shell.execute_reply.started":"2023-04-13T09:31:15.524295Z","shell.execute_reply":"2023-04-13T09:31:15.53107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9 : Splitting the data into training and Validation Split","metadata":{"papermill":{"duration":0.069844,"end_time":"2023-04-08T14:55:59.461622","exception":false,"start_time":"2023-04-08T14:55:59.391778","status":"completed"},"tags":[]}},{"cell_type":"code","source":"x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2,shuffle=True)","metadata":{"papermill":{"duration":0.172387,"end_time":"2023-04-08T14:55:59.705234","exception":false,"start_time":"2023-04-08T14:55:59.532847","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:15.534294Z","iopub.execute_input":"2023-04-13T09:31:15.534776Z","iopub.status.idle":"2023-04-13T09:31:16.654063Z","shell.execute_reply.started":"2023-04-13T09:31:15.534735Z","shell.execute_reply":"2023-04-13T09:31:16.653013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshape image in 3 dimensions (height = 75px, width = 100px , canal = 3)\nx_train = x_train.reshape(x_train.shape[0], *(75, 100, 3))\nx_test = x_test.reshape(x_test.shape[0], *(75, 100, 3))\nx_validate = x_validate.reshape(x_validate.shape[0], *(75, 100, 3))","metadata":{"papermill":{"duration":0.058202,"end_time":"2023-04-08T14:55:59.809335","exception":false,"start_time":"2023-04-08T14:55:59.751133","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:16.655596Z","iopub.execute_input":"2023-04-13T09:31:16.655945Z","iopub.status.idle":"2023-04-13T09:31:16.662145Z","shell.execute_reply.started":"2023-04-13T09:31:16.655909Z","shell.execute_reply":"2023-04-13T09:31:16.660964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train.astype(int)\ny_validate = y_validate.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:31:16.663888Z","iopub.execute_input":"2023-04-13T09:31:16.664598Z","iopub.status.idle":"2023-04-13T09:31:16.672718Z","shell.execute_reply.started":"2023-04-13T09:31:16.664546Z","shell.execute_reply":"2023-04-13T09:31:16.671743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Displaying the total number of images of each Class","metadata":{"papermill":{"duration":0.045372,"end_time":"2023-04-08T14:55:59.899776","exception":false,"start_time":"2023-04-08T14:55:59.854404","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Calculate the number of images in each class for train, validation, and test datasets\ntrain_counts = np.sum(y_train, axis=0)\nval_counts = np.sum(y_validate, axis=0)\ntest_counts = np.sum(y_test, axis=0)\n\n# Print the number of images in each class for train, validation, and test datasets\nprint(\"Dataset Summary\")\nprint(\"-\" * 90)\nprint(f\"{'Class Label':<15} {'Class Name':<30} {'Train':<10} {'Validation':<12} {'Test':<10} {'Total':<10}\")\nprint(\"-\" * 90)\nfor class_label, class_name in label_map.items():\n    train_num = int(train_counts[class_label])\n    val_num = int(val_counts[class_label])\n    test_num = int(test_counts[class_label])\n    total_num = train_num + val_num + test_num\n    print(f\"{class_label:<15} {class_name:<30} {train_num:<10} {val_num:<12} {test_num:<10} {total_num:<10}\")\nprint(\"-\" * 90)\nprint(f\"{'Total':<46} {len(y_train):<10} {len(y_validate):<12} {len(y_test):<10} {len(y_train) + len(y_validate) + len(y_test):<10}\")","metadata":{"papermill":{"duration":0.059918,"end_time":"2023-04-08T14:56:00.005082","exception":false,"start_time":"2023-04-08T14:55:59.945164","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:16.673964Z","iopub.execute_input":"2023-04-13T09:31:16.674396Z","iopub.status.idle":"2023-04-13T09:31:16.68827Z","shell.execute_reply.started":"2023-04-13T09:31:16.674359Z","shell.execute_reply":"2023-04-13T09:31:16.687213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.groupby('label').size()","metadata":{"papermill":{"duration":0.061936,"end_time":"2023-04-08T14:56:00.11278","exception":false,"start_time":"2023-04-08T14:56:00.050844","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:16.689935Z","iopub.execute_input":"2023-04-13T09:31:16.69042Z","iopub.status.idle":"2023-04-13T09:31:16.703524Z","shell.execute_reply.started":"2023-04-13T09:31:16.690319Z","shell.execute_reply":"2023-04-13T09:31:16.702451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape = df['image'][0].shape","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:31:16.704881Z","iopub.execute_input":"2023-04-13T09:31:16.70542Z","iopub.status.idle":"2023-04-13T09:31:16.7106Z","shell.execute_reply.started":"2023-04-13T09:31:16.705378Z","shell.execute_reply":"2023-04-13T09:31:16.709283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10 : Model Architecture","metadata":{"papermill":{"duration":0.047796,"end_time":"2023-04-08T14:56:04.40223","exception":false,"start_time":"2023-04-08T14:56:04.354434","status":"completed"},"tags":[]}},{"cell_type":"code","source":"input_shape = df['image'][0].shape\n\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\n\n\n# Load the InceptionV3 model with pre-trained weights from ImageNet\nbase_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n\n# Add a global average pooling layer to the base model\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\n\n# Add a fully-connected output layer with 'num_classes' units and a softmax activation function\npredictions = Dense(num_classes, activation='softmax')(x)\n\n# Define the new model with the InceptionV3 base model and the additional layers\nmodel = Model(inputs=base_model.input, outputs=predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:31:16.712238Z","iopub.execute_input":"2023-04-13T09:31:16.712788Z","iopub.status.idle":"2023-04-13T09:31:23.509681Z","shell.execute_reply.started":"2023-04-13T09:31:16.712751Z","shell.execute_reply":"2023-04-13T09:31:23.508677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11 : Setting Optimizer","metadata":{"papermill":{"duration":0.047812,"end_time":"2023-04-08T14:56:08.36329","exception":false,"start_time":"2023-04-08T14:56:08.315478","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# compile model\nfrom keras.optimizers import SGD\nopt = SGD(learning_rate=0.001, momentum=0.9)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n\n# Set a learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                            patience=3,\n                                            verbose=1,\n                                            factor=0.5,\n                                            min_lr=0.00001)","metadata":{"papermill":{"duration":0.072304,"end_time":"2023-04-08T14:56:08.483893","exception":false,"start_time":"2023-04-08T14:56:08.411589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:31:23.511155Z","iopub.execute_input":"2023-04-13T09:31:23.511594Z","iopub.status.idle":"2023-04-13T09:31:23.537397Z","shell.execute_reply.started":"2023-04-13T09:31:23.511535Z","shell.execute_reply":"2023-04-13T09:31:23.536424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12: Fitting of model","metadata":{"papermill":{"duration":0.047969,"end_time":"2023-04-08T14:56:08.580204","exception":false,"start_time":"2023-04-08T14:56:08.532235","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Fit the model\nepochs = 50\nbatch_size=32\nhistory = model.fit(x=x_train,\n                    y=y_train,\n                    epochs=epochs,\n                    batch_size=batch_size,\n                    validation_data=(x_validate,y_validate),\n                    callbacks=learning_rate_reduction)","metadata":{"_kg_hide-output":true,"papermill":{"duration":445.934022,"end_time":"2023-04-08T15:03:34.562326","exception":false,"start_time":"2023-04-08T14:56:08.628304","status":"completed"},"tags":[],"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-04-13T09:45:47.336776Z","iopub.execute_input":"2023-04-13T09:45:47.337166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 13 : Model Evaluation","metadata":{"papermill":{"duration":0.307748,"end_time":"2023-04-08T15:03:35.236846","exception":false,"start_time":"2023-04-08T15:03:34.929098","status":"completed"},"tags":[],"_kg_hide-input":false}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(x_train, y_train, verbose=1)\nprint(\"Train: accuracy = %f  ;  loss = %f\" % (accuracy, loss))","metadata":{"papermill":{"duration":1.130804,"end_time":"2023-04-08T15:03:36.677668","exception":false,"start_time":"2023-04-08T15:03:35.546864","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:44:55.093326Z","iopub.execute_input":"2023-04-13T09:44:55.094819Z","iopub.status.idle":"2023-04-13T09:45:09.757327Z","shell.execute_reply.started":"2023-04-13T09:44:55.094778Z","shell.execute_reply":"2023-04-13T09:45:09.756248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(x_test, y_test, verbose=1)\nprint(\"Testing: accuracy = %f  ;  loss = %f\" % (accuracy, loss))","metadata":{"papermill":{"duration":0.835439,"end_time":"2023-04-08T15:03:37.824937","exception":false,"start_time":"2023-04-08T15:03:36.989498","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:45:09.759125Z","iopub.execute_input":"2023-04-13T09:45:09.759545Z","iopub.status.idle":"2023-04-13T09:45:17.207136Z","shell.execute_reply.started":"2023-04-13T09:45:09.759503Z","shell.execute_reply":"2023-04-13T09:45:17.205891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Get the predicted probabilities for the test set\ny_pred_prob = model.predict(x_test)\n\n# Find the class with the highest probability for each sample\ny_pred = np.argmax(y_pred_prob, axis=1)\n\n# Calculate the confusion matrix\ncm = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n\n# Plot the confusion matrix using Seaborn\nsns.heatmap(cm, annot=True, cmap='Blues')","metadata":{"papermill":{"duration":1.551737,"end_time":"2023-04-08T15:03:39.710856","exception":false,"start_time":"2023-04-08T15:03:38.159119","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:45:17.208695Z","iopub.execute_input":"2023-04-13T09:45:17.209665Z","iopub.status.idle":"2023-04-13T09:45:23.437475Z","shell.execute_reply.started":"2023-04-13T09:45:17.209618Z","shell.execute_reply":"2023-04-13T09:45:23.436459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\nprecision = precision_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nrecall = recall_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nf1 = f1_score(np.argmax(y_test, axis=1), y_pred, average='macro')\nkappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1:.4f}\")\nprint(f\"Kappa score: {kappa:.4f}\")","metadata":{"papermill":{"duration":0.34869,"end_time":"2023-04-08T15:03:40.378395","exception":false,"start_time":"2023-04-08T15:03:40.029705","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:45:23.43925Z","iopub.execute_input":"2023-04-13T09:45:23.440009Z","iopub.status.idle":"2023-04-13T09:45:23.460931Z","shell.execute_reply.started":"2023-04-13T09:45:23.43997Z","shell.execute_reply":"2023-04-13T09:45:23.459989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Get training and testing accuracy and loss histories\ntraining_accuracy = history.history['accuracy']\ntesting_accuracy = history.history['val_accuracy']\ntraining_loss = history.history['loss']\ntesting_loss = history.history['val_loss']\n\n# Plot training and testing accuracy curves\nplt.plot(training_accuracy)\nplt.plot(testing_accuracy)\nplt.title('Training vs Testing Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Testing'], loc='lower right')\nplt.show()\n\n# Plot training and testing loss curves\nplt.plot(training_loss)\nplt.plot(testing_loss)\nplt.title('Training vs Testing Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training', 'Testing'], loc='upper right')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-13T09:45:23.462477Z","iopub.execute_input":"2023-04-13T09:45:23.462896Z","iopub.status.idle":"2023-04-13T09:45:23.893604Z","shell.execute_reply.started":"2023-04-13T09:45:23.462857Z","shell.execute_reply":"2023-04-13T09:45:23.892509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 14 : Saving the model","metadata":{"papermill":{"duration":0.312943,"end_time":"2023-04-08T15:03:42.162912","exception":false,"start_time":"2023-04-08T15:03:41.849969","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model.save(\"skinDiseaseDetectionUsningCNN.h5\")","metadata":{"papermill":{"duration":0.371481,"end_time":"2023-04-08T15:03:42.849757","exception":false,"start_time":"2023-04-08T15:03:42.478276","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-04-13T09:45:23.894864Z","iopub.execute_input":"2023-04-13T09:45:23.895203Z","iopub.status.idle":"2023-04-13T09:45:23.900252Z","shell.execute_reply.started":"2023-04-13T09:45:23.895165Z","shell.execute_reply":"2023-04-13T09:45:23.899149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.341888,"end_time":"2023-04-08T15:03:43.50365","exception":false,"start_time":"2023-04-08T15:03:43.161762","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}